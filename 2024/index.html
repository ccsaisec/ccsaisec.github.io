<!DOCTYPE html>
<html lang="en">
    <head>
        <meta name="generator" content="HTML Tidy for HTML5 for Apple macOS version 5.6.0">
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <meta name="description" content="AI and Security Workshop (AISec)">
        <meta name="keywords" content="Deep Learning, Machine Learning, Security, Adversarial Examples, Attacks, Intrusion Detection, Program Analysis, Malware, Botnets, Vulnerability, Phishing, Forensics, Neural Networks, Recurrent Networks, Generative Adversarial Networks, AISec">
        <meta name="author" content="AISec Chairs">
        <title>17th ACM Workshop on Artificial Intelligence and Security (AISec 2024)</title>
        <link
            href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css"
            rel="stylesheet"
            integrity="sha384-KK94CHFLLe+nY2dmCWGMq91rCGa5gtU4mk92HdvYe+M/SXH301p5ILy+dN9+nJOZ"
            crossorigin="anonymous"
        >
        <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=K2D:400,700" rel="stylesheet" type="text/css">
        <!-- Custom styles for this template -->
        <link href="css/agency.css" rel="stylesheet">
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-QDQDHN7F62"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-QDQDHN7F62');
        </script>
    </head>
    <body id="page-top">
        <!-- Navigation -->
        <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="#page-top">AISec 2024</a>
                <button
                    class="navbar-toggler navbar-toggler-right"
                    type="button"
                    data-toggle="collapse"
                    data-target="#navbarResponsive"
                    aria-controls="navbarResponsive"
                    aria-expanded="false"
                    aria-label="Toggle navigation"
                >Menu</button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ml-auto">
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#page-top">Home</a>
                        </li>
                        <!-- <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#keynote">Keynotes</a>
                        </li> -->
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#programme">Programme</a>
                        </li>
                        <!-- <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#accepted">Accepted Papers</a>
                        </li> -->
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#cfp">Call for Papers</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#award">Best Paper Award</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#committee">Committee</a>
                        </li>
                        <li class="nav-item dropdown">
                            <li class="nav-item dropdown">
                                <a
                                    class="nav-link dropdown-toggle"
                                    href="#"
                                    role="button"
                                    id="navbarDropdown"
                                    data-bs-toggle="dropdown"
                                    aria-expanded="false"
                                >Past Editions</a>
                                <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <li>
                                        <a class="dropdown-item" href="2023/index.html">2023</a>
                                    </li>
                                </ul>
                            </li>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" target="_blank" href="https://www.sigsac.org/ccs/CCS2024/">ACM CCS</a>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Header -->
        <header class="masthead">
            <div class="container">
                <div class="intro-text">
                    <div class="intro-heading">
                        17
                        <sup>
                            <small>
                                <b>th</b>
                            </small>
                        </sup>
                        ACM Workshop on
                        <br>
                        Artificial Intelligence and Security
                    </div>
                    <div class="intro-lead-in">
                        <b>October 18th, 2024 — Salt Lake City</b>
                        Grand Ballroom, Salon E
                    </div>
                    <div class="intro-lead-in">
                        co-located with the 31st ACM Conference on Computer and Communications Security
                    </div>
                    <div class="photo-credit">
                        Photo:
                        <a target="_blank" href="https://it.wikipedia.org/wiki/Salt_Lake_City#/media/File:Salt_Lake_City_-_July_16,_2011.jpg">Wikipedia</a>
                        (License:
                        <a href="https://creativecommons.org/licenses/by/2.0/">
                            CC BY 2.0
                        </a>
                        )
                    </div>
                </div>
            </div>
        </header>
        <section id="keynote">
            <div class="container">
                <div class="row">
                    <h2 class="section-heading text-uppercase">Keynotes</h2>
                </div>
                <div class="row">
                    <div class="col-lg-3">
                        <center>
                            <img src="img/alina.jpg" class="portait">
                        </center>
                    </div>
                    <div class="col-lg-9 text-justify">
                        <h3 class="section-subheading">
                            <b>Title: On the Security and Privacy Risks of Generative AI Systems</b>
                        </h3>
                        <details>
                            <summary>
                                <b>Alina Oprea, Professor @ Northeastern University</b>
                            </summary>
                            <p>Alina Oprea is a Professor at Northeastern University in the Khoury College of Computer Sciences. She joined Northeastern University in Fall 2016 after spending 9 years as a research scientist at RSA Laboratories. Her research interests in cyber security are broad, with a focus on AI security and privacy, ML-based threat detection, cloud security, and applied cryptography. She is the recipient of the Technology Review TR35 award for her research in cloud security in 2011, the Google Security and Privacy Award in 2019, the Ruth and Joel Spira Award for Excellence in Teaching in 2020, and the CMU Cylab Distinguished Alumni Award in 2024. Alina served as Program Committee co-chair of the flagship cyber security conference, the IEEE Security and Privacy Symposium in 2020 and 2021. She also served as Associate Editor of the ACM Transactions of Privacy and Security( TOPS) journal and the IEEE Security and Privacy Magazine. Her work was recognized with Best Paper Awards at NDSS 2005, AISEC in 2017, and GameSec in 2019..</p>
                        </details>
                        <p>
                            In the last few years, we have seen tremendous progress on the capabilities of generative AI and large language models (LLMs). As model sizes have reached hundreds of billions of parameters, training models from scratch has become infeasible. Consequently, system developers typically leverage pre-trained LLMs, and later fine-tune them or augment them with external content to specialize them to new tasks. In this talk, we pose the question if these complex LLM deployment pipelines introduce new security and privacy risks for users. We discuss a new privacy attack on fine-tuned LLMs and a new poisoning attack for LLMs utilizing Retriever Augmented Generation (RAG). We also discuss the challenges of developing mitigations and highlight several open problems in securing AI systems.
                        </p>
                    </div>
                </div>
                <div class="row">
                    <div class="col-lg-3">
                        <center>
                            <img src="img/lea.jpg" class="portait">
                        </center>
                    </div>
                    <div class="col-lg-9 text-justify">
                        <h3 class="section-subheading">
                            <b>Title: Challenges and Threats in Generative AI: Misuse and Exploits</b>
                        </h3>
                        <details>
                            <summary>
                                <b>Lea Schönherr, Tenure-track Faculty @ CISPA Helmholtz Center for Information Security</b>
                            </summary>
                            <p>
                                Lea Schönherr is a tenure-track faculty at CISPA Helmholtz Center for Information Security since 2022. Her research focuses on information security, particularly adversarial machine learning, trustworthy generative AI, and ML security applications. She is especially interested in language as an interface to machine learning models, including their cognitive representations and code generation with LLMs. She has published several papers on threat detection and defense of speech recognition systems, generative models, and preventing the misuse of generative AI. She obtained her PhD from Ruhr-Universität Bochum, Germany, in 2021 and is a recipient of two fellowships from UbiCrypt (DFG Graduate School) and Casa (DFG Cluster of Excellence).
                            </p>
                            <br>
                        </details>
                        <p>
                            Generative AI (genAI) is becoming more integrated into our daily lives, raising questions about potential threats within genAI systems and their outputs. In this talk, we will examine the resulting challenges and security threats associated with generative AI.

                            In the first part of the talk, we look at threat scenarios in which generative models are utilized to produce content that is impossible to distinguish from human-generated content. This fake content is often used for fraudulent and manipulative purposes. As generative models evolve, the attacks are easier to automate and require less expertise, while detecting such activities will become increasingly difficult. This talk will provide an overview of our current challenges in detecting fake media in human and machine interactions.
                            
                            The second part will cover exploits of LLMs to disrupt alignment or to steal sensitive information. Existing attacks show that content filters of LLMs can be easily bypassed with specific inputs and that private information can be leaked. Also, established methods in the adversarial machine learning field cannot be easily transferred to generative models. From an alternative perspective, we show that an alternative way to protect intellectual property is by obfuscating prompts. We demonstrate that with only some overhead, we can achieve similar utility while protecting confidential data.
                            
                            The final part of the presentation will discuss the use of generative models in security applications. This includes benchmarking and fixing vulnerable code and understanding these models' capabilities by investigating their code deobfuscation abilities.
                        </p>
                        <a href="media/aisec_schoenherr.pdf">Slides</a>
                        <p></p>
                    </div>
                </div>
                <div class="row">
                    <div class="col-lg-3">
                        <center>
                            <img src="img/giovanni.jpg" class="portait">
                        </center>
                    </div>
                    <div class="col-lg-9 text-justify">
                        <h3 class="section-subheading">
                            <b>Title: A threat-centric look at Privacy-Preserving Machine Learning</b>
                        </h3>
                        <details>
                            <summary>
                                <b>Giovanni Cherubin, Senior Researcher @ Microsoft</b>
                            </summary>
                            <p>
                                Giovanni Cherubin is a Senior Researcher at Microsoft in Cambridge, working with the Microsoft Security Response Centre (MSRC). Before joining Microsoft, Giovanni held research positions at the Alan Turing Institute and EPFL. He obtained a PhD in Machine Learning and Cyber Security from Royal Holloway University of London. His research focuses on the privacy and security properties of machine learning models, as well as the theoretical and empirical study of their information leakage. Additionally, Giovanni works on distribution-free uncertainty estimation for machine learning, such as Conformal Prediction. He has received multiple awards for his contributions to security, privacy, and distribution-free inference.
                            </p>
                        </details>
                        <p>
                            Privacy-preserving Machine Learning (PPML) has the rare privilege among security research fields of having defences that are both practical and theoretically robust, thanks to over 20 years of progress. However, deployment of these defenses often sparks heated debates over how to tune their parameters. This is partially because these defences are typically designed to counter "any" attack, which can lead to overlooking the specific threats relevant to a particular deployment. 
                            This talk will cover the key advancements in PPML research through the principle of "first consider the threats, then pick a defence." By deliberately defining which attacks we consider to be a threat (and which ones we don't) before deploying a model, we can more effectively select concrete parameters for our defences, and better communicate the extent and limitations of the protection we've achieved.
                        </p>
                        <p></p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section class="bg-light" id="programme">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-justify">
                    <h2 class="section-heading text-uppercase">Programme</h2>
                    <table cellpadding="5">
                        <p>The following times are on MDT (Mountain Daylight Time) UTC/GMT -6 hours.</p>
                        <tr>
                            <td class="orga" width="120px">09:00&ndash;9:15</td>
                            <td class="orga">Opening and Welcome</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">9:15&ndash;10:00</td>
                            <td class="orga uline">Keynote 1</td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">On the Security and Privacy Risks of Generative AI Systems</em>
                                <br>
                                <b>Alina Oprea</b>
                                , Professor @ Northeastern University
                            </td>
                        </tr>
                        <tr>
                            <td class="orga">10:00-10:30</td>
                            <td class="orga uline">Spotlights</td>
                            <tr>
                                <td></td>
                                <td>
                                    <em class="paper">Efficient Model Extraction via Boundary Sampling</em>
                                    <br>
                                    <b>Authors</b>
                                    :
                                    <u>Maor Biton Dor</u>
                                    (Ben-Gurion University), Yisroel Mirsky (Ben-Gurion University)
                                </td>
                            </tr>
                            <tr>
                                <td></td>
                                <td>
                                    <em class="paper">Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks</em>
                                    <br>
                                    <b>Authors</b>
                                    :
                                    <u>Dario Pasquini</u>
                                    (George Mason University), Martin Strohmeier (Cyber-Defence Campus, armasuisse Science + Technology), Carmela Troncoso (EPFL)
                                </td>
                            </tr>
                            <tr>
                                <td></td>
                                <td>
                                    <em class="paper">Harmful Bias: A General Label-Leakage Attack on Federated Learning from Bias Gradients</em>
                                    <br>
                                    <b>Authors</b>
                                    :
                                    <u>Nadav Gat</u>
                                    (Tel Aviv University), Mahmood Sharif (Tel Aviv University)
                                </td>
                            </tr>
                            <tr>
                                <td></td>
                                <td>
                                    <em class="paper">Offensive AI: Enhancing Directory Brute-forcing Attack with the Use of Language Models</em>
                                    <br>
                                    <b>Authors</b>
                                    :
                                    <u>Alberto Castagnaro</u>
                                    (Delft University of Technology, The Netherlands), Mauro Conti (University of Padua, Italy), Luca Pajola (University of Padua, Italy)
                                </td>
                            </tr>
                        </tr>
                        <tr>
                            <td class="orga">10:30&ndash;11:00</td>
                            <td class="orga">Coffee break</td>
                        </tr>
                        <tr>
                            <td class="orga">11:00&ndash;12:00</td>
                            <td class="orga uline">Poster session 1 - Skylight room (2nd floor)</td>
                        </tr>
                        <tr>
                            <td class="orga">12:00&ndash;13:30</td>
                            <td class="orga">Lunch</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">13:30&ndash;14:15</td>
                            <td class="orga uline">
                                Keynote 2
                                <br>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Challenges and Threats in Generative AI: Misuse and Exploits</em>
                                <br>
                                <b>Lea Schönherr</b>
                                , Tenure-track Faculty @ CISPA Helmholtz Center for Information Security
                            </td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">14:15&ndash;15:00</td>
                            <td class="orga uline">
                                Keynote 3
                                <br>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">A threat-centric look at Privacy-Preserving Machine Learning</em>
                                <br>
                                <b>Giovanni Cherubin</b>
                                , Senior Researcher @ Microsoft
                            </td>
                        </tr>
                        <tr>
                            <td class="orga">15:00&ndash;15:30</td>
                            <td class="orga">Coffee break</td>
                        </tr>
                    </tr>
                    <tr>
                        <td class="orga">15:30&ndash;16:30</td>
                        <td class="orga uline">Poster session 2 - Grand Ballroom E</td>
                    </tr>
                    <tr>
                        <td class="orga">16:30&ndash;16:45</td>
                        <td class="orga">Closing remarks</td>
                    </tr>
                </table>
            </div>
        </div>
    </div>
    <section id="award">
        <div class="container">
            <div class="col-lg-12 text-justify">
                <h2 class="section-heading text-uppercase">Best Paper Award</h2>
                <p>
                    As in the previous editions of this workshop, we would honor outstanding contributions.
                To this end, we will award the best paper, selected by the reviewers
                among all the submitted papers.
                </p>
                <p>
                    The 2024 AISec Best Paper Award was given to:
                    <br>
                    <strong>Maor Biton Dor</strong>
                    (Ben-Gurion University),
                    <strong>Yisroel Mirsky</strong>
                    (Ben-Gurion University),
                for the paper
                    <strong>Efficient Model Extraction via Boundary Sampling</strong>
                    .
                </p>
            </div>
        </div>
    </section>
    <section id="accepted">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-justify">
                    <h2 class="section-heading text-uppercase">Accepted Papers</h2>
                    <p>
                        You can find the accepted papers in the
                        <a href="https://dl.acm.org/doi/proceedings/10.1145/3689932">proceedings</a>
                        .
                    </p>
                    <strong>Machine Learning Security (Poster session 1)</strong>
                    <table cellpadding="5">
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Semantic Stealth: Crafting Covert Adversarial Patches for Sentiment Classifiers Using Large Language Models</em>
                                <br>
                                <b>Authors</b>
                                : Camila Roa (Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, TN), Maria Mahbub (Center for Artificial Intelligence Security Research, Oak Ridge National Laboratory, Oak Ridge, TN), Sudarshan Srinivasan (Center for Artificial Intelligence Security Research, Oak Ridge National Laboratory, Oak Ridge, TN), Edmon Begoli (Center for Artificial Intelligence Security Research, Oak Ridge National Laboratory, Oak Ridge, TN), Amir Sadovnik (Center for Artificial Intelligence Security Research, Oak Ridge National Laboratory, Oak Ridge, TN)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Getting a-Round Guarantees: Floating-Point Attacks on Certified Robustness</em>
                                <br>
                                <b>Authors</b>
                                : Jiankai Jin (The University of Melbourne), Olga Ohrimenko (The University of Melbourne), Benjamin I. P. Rubinstein (The University of Melbourne)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">On the Robustness of Graph Reduction Against GNN Backdoor</em>
                                <br>
                                <b>Authors</b>
                                : Yuxuan Zhu (Rensselaer Polytechnic Institute), Michael Mandulak (Rensselaer Polytechnic Institute), Kerui Wu (Rensselaer Polytechnic Institute), George Slota (Rensselaer Polytechnic Institute), Yuseok Jeon (Ulsan National Institute of Science and Technology), Ka-Ho Chow (The University of Hong Kong), Lei Yu (Rensselaer Polytechnic Institute)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Adversarially Robust Anti-Backdoor Learning</em>
                                <br>
                                <b>Authors</b>
                                : Qi Zhao (Karlsruhe Institute of Technology (KIT)), Christian Wressnegger (Karlsruhe Institute of Technology (KIT))
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks</em>
                                <br>
                                <b>Authors</b>
                                :
                                
                                    Dario Pasquini (George Mason University), Martin Strohmeier (Cyber-Defence Campus, armasuisse Science + Technology), Carmela Troncoso (EPFL)
                                <br>
                                <a href="https://drive.google.com/file/d/1V-WzCWEXyJyTWLvw9y9abaPZD7CnBPkm/view?usp=share_link">Video</a>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Adversarial Feature Alignment: Balancing Robustness and Accuracy in Deep Learning via Adversarial Training</em>
                                <br>
                                <b>Authors</b>
                                : Leo Hyun Park (Yonsei University), Jaeuk Kim (Yonsei University), Myung Gyo Oh (Yonsei University), Jaewoo Park (Yonsei University), Taekyoung Kwon (Yonsei University)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">The Ultimate Combo: Boosting Adversarial Example Transferability by Composing Data Augmentations</em>
                                <br>
                                <b>Authors</b>
                                : Zebin Yun (Tel Aviv University), Achi-Or Weingarten (Weizmann Institute of Science), Eyal Ronen (Tel Aviv University), Mahmood Sharif (Tel Aviv University)
                                <br>
                                <a href="media/aisec_yun.pdf">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">ELMs Under Siege: A Study on Backdoor Attacks on Extreme Learning Machines</em>
                                <br>
                                <b>Authors</b>
                                : Behrad Tajalli (Radboud University), Stefanos Koffas (TU Delft), Gorka Abad (Radboud University & Ikerlan Technology Research Centre, Basque Research and Technology Alliance (BRTA)), Stjepan Picek (Radboud University)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">EmoBack: Backdoor Attacks Against Speaker Identification Using Emotional Prosody</em>
                                <br>
                                <b>Authors</b>
                                : Coen Schoof (Radboud University), Stefanos Koffas (Delft University of Technology), Mauro Conti (University of Padua), Stjepan Picek (Radboud University)
                            </td>
                        </tr>
                    </table>
                    <strong>Privacy-Preserving Machine Learning (Poster session 2)</strong>
                    <table cellpadding="5">
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Efficient Model Extraction via Boundary Sampling</em>
                                <br>
                                <b>Authors</b>
                                : Maor Biton Dor (Ben-Gurion University), Yisroel Mirsky (Ben-Gurion University)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Feature Selection from Differentially Private Correlations</em>
                                <br>
                                <b>Authors</b>
                                : Ryan Swope (Booz Allen Hamilton), Amol Khanna (Booz Allen Hamilton), Philip Doldo (Booz Allen Hamilton), Saptarshi Roy (University of Michigan, Ann Arbor), Edward Raff (Booz Allen Hamiltion)
                                <br>
                                <a href="media/aisec_swope.pdf">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">It's Our Loss: No Privacy Amplification for Hidden State DP-SGD With Non-Convex Loss</em>
                                <br>
                                <b>Authors</b>
                                : Meenatchi Sundaram Muthu Selva Annamalai (meenatchi.annamalai.22@ucl.ac.uk)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Harmful Bias: A General Label-Leakage Attack on Federated Learning from Bias Gradients</em>
                                <br>
                                <b>Authors</b>
                                : Nadav Gat (Tel Aviv University), Mahmood Sharif (Tel Aviv University)
                                <br>
                                <a href="media/aisec_gat.pdf">Poster</a>
                            </td>
                        </tr>
                    </table>
                    <strong>System Security (Poster session 2)</strong>
                    <table cellpadding="5">
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">When Adversarial Perturbations meet Concept Drift: an Exploratory Analysis on ML-NIDS</em>
                                <br>
                                <b>Authors</b>
                                : Giovanni Apruzzese (University of Liechtenstein), Aurore Fass (CISPA Helmholtz Center for Information Security), Fabio Pierazzi (King's College London)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Towards Robust, Explainable, and Privacy-Friendly Sybil Detection</em>
                                <br>
                                <b>Authors</b>
                                : Christian Bungartz (University of Bonn), Dr. Felix Boes (University of Bonn), Prof. Dr. Michael Meier (University of Bonn, Fraunhofer FKIE), Dr. Marc Ohm (University of Bonn, Fraunhofer FKIE)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Using LLM Embeddings with Similarity Search for Botnet TLS Certificate Detection</em>
                                <br>
                                <b>Authors</b>
                                : Kumar Shashwat (University of South Florida), Francis Hahn (University of South Florida), Stuart Millar (Rapid7 LLC), Xinming Ou (University of South Florida)
                                <br>
                                <a href="media/aisec_shashwat.pdf">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Offensive AI: Enhancing Directory Brute-forcing Attack with the Use of Language Models</em>
                                <br>
                                <b>Authors</b>
                                : Alberto Castagnaro (Delft University of Technology, The Netherlands), Mauro Conti (University of Padua, Italy), Luca Pajola (University of Padua, Italy)
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Music to My Ears: Turning GPU Sounds into Intellectual Property Gold</em>
                                <br>
                                <b>Authors</b>
                                : Sayed Erfan Arefin (Texas Tech University), Abdul Serwadda (Texas Tech University)
                                <br>
                                <a href="media/aisec_arefin.pdf">Poster</a>
                                <a href="https://eu-central-1.protection.sophos.com/?d=youtu.be&u=aHR0cHM6Ly95b3V0dS5iZS9JWjNlM0E5bWVnMA==&i=NjUwODE5MDZhZGJjMGUzNGNhODBiZTJh&t=Withc2Fvc3hQSHJPK2QwdTgwUDBXMUZEakZnb3lyQi92czEySlQzYWVJND0=&h=33d288306fe24ee1b5a921e7da098f18&s=AVNPUEhUT0NFTkNSWVBUSVZXFuMVUPFYwoz7CFbpU-9Nq_0qJ89vs0tRiJyB7_OkgQ">Video</a>
                            </td>
                        </tr>
                    </table>
                </div>
            </div>
        </section>
        <section id="cfp">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-justify">
                        <h2 class="section-heading text-uppercase">Call for Papers</h2>
                        <h3 class="section-subheading">Important Dates</h3>
                        <ul>
                            <li>
                                Paper submission deadline:
                                <s>June 21st</s>
                                July 7th, 2024, 11:59 PM (all deadlines are AoE, UTC-12)
                            </li>
                            <li>
                                Reviews due:
                                <s>July 19th</s>
                                July 31st, 2024
                            </li>
                            <li>
                                Review Released and Acceptance notification:
                                <s>August 2nd</s>
                                August 6th, 2024
                            </li>
                            <li>
                                Camera ready due:
                                <s>August 22nd</s>
                                September 20th, 2024
                            </li>
                            <li>Workshop day: October 18th, 2024</li>
                        </ul>
                        <h3 class="section-subheading">Overview</h3>
                        <p>
                            Recent years have seen a dramatic increase in applications of Artificial Intelligence (AI), Machine Learning (ML), and data mining to security and privacy problems. The analytic tools and intelligent behavior provided by these techniques make AI and ML increasingly important for autonomous real-time analysis and decision making in domains with a wealth of data or that require quick reactions to constantly changing situations. The use of learning methods in security-sensitive domains, in which adversaries may attempt to mislead or evade intelligent machines, creates new frontiers for security research. The recent widespread adoption of “deep learning” techniques, whose security properties are difficult to reason about directly, has only added to the importance of this research. In addition, data mining and machine learning techniques create a wealth of privacy issues, due to the abundance and accessibility of data. The AISec workshop provides a venue for presenting and discussing new developments in the intersection of security and privacy with AI and ML.
                        </p>
                        <h3 class="section-subheading">Topics of Interest</h3>
                        <p>Topics of interest include (but are not limited to):</p>
                        <p>
                            <b>Theoretical topics related to security</b>
                        </p>
                        <ul>
                            <li>Adversarial learning</li>
                            <li>Security of deep learning systems</li>
                            <li>Robust statistics</li>
                            <li>Learning in games</li>
                            <li>Economics of security</li>
                            <li>Differential privacy</li>
                        </ul>
                        <p>
                            <b>Security applications</b>
                        </p>
                        <ul>
                            <li>Computer forensics</li>
                            <li>Spam detection</li>
                            <li>Phishing detection and prevention</li>
                            <li>Botnet detection</li>
                            <li>Intrusion detection and response</li>
                            <li>Malware identification and analysis</li>
                            <li>Data anonymization/de-anonymization</li>
                            <li>Security in social networks</li>
                            <li>Big data analytics for security</li>
                            <li>User authentication</li>
                        </ul>
                        <p>
                            <b>Security-related AI problems</b>
                            <p>
                                <ul>
                                    <li>Distributed inference and decision making for security</li>
                                    <li>Secure multiparty computation and cryptographic approaches</li>
                                    <li>Model confidentiality</li>
                                    <li>Privacy-preserving data mining</li>
                                    <li>Adaptive side-channel attacks</li>
                                    <li>Design and analysis of CAPTCHAs</li>
                                    <li>AI approaches to trust and reputation</li>
                                    <li>Vulnerability testing through intelligent probing (e.g. fuzzing)</li>
                                    <li>Content-driven security policy management & access control</li>
                                    <li>Techniques and methods for generating training and test sets</li>
                                    <li>Anomalous behavior detection (e.g. for the purpose of fraud detection)</li>
                                    <li>AI Misuse (e.g., Large Language Models for automated hacking, misinformation, deepfakes)</li>
                                    <li>Safety and ethical issues of Generative AI</li>
                                </ul>
                                <h3 class="section-subheading">Submission Guidelines</h3>
                                <p>
                                    We invite the following types of papers:
                                    <ul>
                                        <li>
                                            <b>Original research papers</b>
                                            on any topic in the intersection of AI or machine learning
                            with security, privacy, or related areas.
                                        </li>
                                        <li>
                                            <b>Position and open-problem papers</b>
                                            discussing the relationship of AI or machine
                            learning to security or privacy. Submitted papers of this type may not substantially overlap
                            with papers that have been published previously or that are simultaneously submitted to a
                            journal or conference/workshop proceedings.
                                        </li>
                                        <li>
                                            <b>Systematization-of-knowledge papers</b>
                                            , which should distill the AI or machine learning
                            contributions of a previously-published series of security papers.
                                        </li>
                                    </ul>
                                </p>
                                <p>
                                    The authors can specify the paper type in the submission form. Paper submissions must be at most
                        10 pages in double-column ACM format, excluding the bibliography and well-marked appendices, and
                        at most 12 pages overall.
                        Papers should be in LaTeX and we recommend using the ACM format. This format is required for the
                        camera-ready version. Please follow the main CCS formatting instructions (except with page
                        limits as described above). In particular, we recommend using the sigconf template, which can be
                        downloaded from
                                    <a href="https://www.acm.org/publications/proceedings-template" target="_blank">https://www.acm.org/publications/proceedings-template</a>
                                    . Accepted papers
                        will be published by the ACM Digital Library and/or ACM Press. Committee members are not
                        required to read the appendices, so the paper should be intelligible without them.
                                    <u>Submissions must be in English and properly anonymized.</u>
                                </p>
                                <h3 class="section-subheading">Submission Site</h3>
                                <p>
                                    Submission link:
                                    <a href="https://aisec2024.hotcrp.com" target="_blank">https://aisec2024.hotcrp.com</a>
                                    .
                                </p>
                                <p>
                                    All accepted submissions will be presented at the workshop as posters. Accepted papers 
                        will be selected for presentation as spotlights based on their review score and novelty. 
                        Nonetheless, all accepted papers should be considered as having equal importance and 
                        will be included in the ACM workshop proceedings.
                                </p>
                                <p>
                                    One author of each accepted paper is required to attend the workshop and present the paper for
                        it to be included in the proceedings.
                                </p>
                                <p>
                                    For any questions, please contact one the workshop organizers at
                                    <a href="mailto:maura.pintor@unica.it">maura.pintor@unica.it</a>
                                </p>
                            </div>
                        </div>
                    </div>
                </section>
            </section>
            <section id="committee" class="bg-light">
                <div class="container">
                    <div class="row">
                        <div class="col-lg-12 text-left">
                            <h2 class="section-heading text-uppercase">Committee</h2>
                            <h3 class="section-subheading">Workshop Chairs</h3>
                            <ul class="noindent">
                                <li>
                                    <a href="https://maurapintor.github.io/" target="_blank">Maura Pintor</a>
                                    ,
                            University of Cagliari, Italy
                                </li>
                                <li>
                                    <a href="https://jungyhuk.github.io/" target="_blank">Xinyun Chen</a>
                                    , Google DeepMind, USA
                                </li>
                                <li>
                                    <a href="https://jagielski.github.io" target="_blank">Matthew Jagielski</a>
                                    , Google LLC,
                            USA
                                </li>
                            </ul>
                            <h3 class="section-subheading">Steering Committee</h3>
                            <ul class="noindent">
                                <li>
                                    <a href="http://theory.stanford.edu/~dfreeman/" target="_blank">David Freeman</a>
                                    , Facebook,
                            Inc.
                                </li>
                                <li>
                                    <a href="https://cis.unimelb.edu.au/people/staff.php?person_ID=20074/" target="_blank">Benjamin Rubinstein</a>
                                    , University of Melbourne
                                </li>
                                <li>
                                    <a href="https://pralab.diee.unica.it/en/BattistaBiggio/" target="_blank">
                                        Battista
                                Biggio
                                    </a>
                                    , University of Cagliari & PluribusOne
                                </li>
                            </ul>
                            <h3 class="section-subheading">Program Committee</h3>
                            <h5>Top Reviewers</h5>
                            <div class="row">
                                <div class="col">
                                    <ul class="noindent">
                                        <li>
                                            Aideen Fay (Microsoft)
                                        </li>
                                        <li>
                                            Andrew Cullen (University of Melbourne)
                                        </li>
                                        <li>
                                            Andy Applebaum (Apple)
                                        </li>
                                        <li>
                                            Angelo Sotgiu (University of Cagliari)
                                        </li>
                                        <li>
                                            Balachandra Shanabhag (Cohesity)
                                        </li>
                                        <li>
                                            Bhavna Soman (Amazon Web Services)
                                        </li>
                                        <li>
                                            Boyang Zhang (CISPA Helmholtz Center for Information Security)
                                        </li>
                                        <li>
                                            Brad Miller (X Corp)
                                        </li>
                                        <li>
                                            Christian Wressnegger (Karlsruhe Institute of Technology)
                                        </li>
                                        <li>
                                            Diego Soi (University of Cagliari)
                                        </li>
                                        <li>
                                            Edward Raff (Booz Allen Hamiltion)
                                        </li>
                                        <li>
                                            Erwin Quiring (Ruhr University Bochum and ICSI)
                                        </li>
                                        <li>
                                            Eva Giboulot (Linkmedia - INRIA Rennes)
                                        </li>
                                        <li>
                                            Fabio Brau (Scuola Superiore Sant'Anna)
                                        </li>
                                        <li>
                                            Giorgio Piras (University of Cagliari)
                                        </li>
                                        <li>
                                            Giulio Rossolini (Scuola Superiore Sant'Anna)
                                        </li>
                                        <li>
                                            Ilias Tsingenopoulos (DistriNet, KU Leuven)
                                        </li>
                                        <li>
                                            James Hu (University of Arizona)
                                        </li>
                                        <li>
                                            Joel Frank (Meta)
                                        </li>
                                        <li>
                                            John Holodnak (MIT Lincoln Laboratory)
                                        </li>
                                        <li>
                                            Jonas Möller (TU Berlin)
                                        </li>
                                        <li>
                                            Jose Maria de Fuentes (Universidad Carlos III de Madrid)
                                        </li>
                                    </ul>
                                </div>
                                <div class="col">
                                    <ul class="noindent">
                                        <li>
                                            Kathrin Grosse (EPFL)
                                        </li>
                                        <li>
                                            Lea Schönherr (CISPA Helmholtz Center for Information Security)
                                        </li>
                                        <li>
                                            Lorenzo Cazzaro (Università Ca' Foscari Venezia)
                                        </li>
                                        <li>
                                            Luca Demetrio (University of Genoa)
                                        </li>
                                        <li>
                                            Maria Rigaki (Czech Technical University in Prague)
                                        </li>
                                        <li>
                                            Maximilian Noppel (Karlsruhe Institute of Technology)
                                        </li>
                                        <li>
                                            Patrick Dwyer (Apple, Inc)
                                        </li>
                                        <li>
                                            Sam Bretheim (Craigslist)
                                        </li>
                                        <li>
                                            Scott Coull (Google)
                                        </li>
                                        <li>
                                            Shae McFadden (King's College London & The Alan Turing Institute)
                                        </li>
                                        <li>
                                            Theo Chow (King's College London)
                                        </li>
                                        <li>
                                            Thorsten Eisenhofer (TU Berlin)
                                        </li>
                                        <li>
                                            Tobias Lorenz (CISPA Helmholtz Center for Information Security)
                                        </li>
                                        <li>
                                            Wenjun Zhu (Zhejiang University)
                                        </li>
                                        <li>
                                            Xiaoyu Ji (Zhejiang University)
                                        </li>
                                        <li>
                                            Xin Fan Guo (King's College London)
                                        </li>
                                        <li>
                                            Xinyue Shen (CISPA Helmholtz Center for Information Security)
                                        </li>
                                        <li>
                                            Yue Zhao (Institute of Information Engineering, Chinese Academy of Sciences)
                                        </li>
                                        <li>
                                            Zied Ben Houidi (Huawei Technologies Co. Ltd.)
                                        </li>
                                        <li>
                                            Ziqi Yang (Zhejiang University)
                                        </li>
                                    </ul>
                                </div>
                            </div>
                            <h5>Reviewers</h5>
                            <div class="row">
                                <div class="col">
                                    <ul class="noindent">
                                        <li>Abbas Yazdinejad (University of Guelph, Canada)</li>
                                        <li>Achin (Ace) Kulshrestha (Google Inc.)</li>
                                        <li>Alessandro Brighente (University of Padova)</li>
                                        <li>Alessandro Erba (Karlsruhe Institute of Technology)</li>
                                        <li>Alessandro Sanna (University Of Cagliari)</li>
                                        <li>Ambrish Rawat (IBM Research)</li>
                                        <li>Annalisa Appice (University of Bari Aldo Moro)</li>
                                        <li>Anshuman Suri (University of Virginia)</li>
                                        <li>Antonio Emanuele Cinà (University of Genoa)</li>
                                        <li>Arjun Bhagoji (University of Chicago)</li>
                                        <li>Arnav Garg (Microsoft)</li>
                                        <li>Azqa Nadeem (University of Twente)</li>
                                        <li>Bailey Kacsmar (University of Alberta)</li>
                                        <li>Benjamin M. Ampel (Georgia State University)</li>
                                        <li>Bobby Filar (Sublime Security)</li>
                                        <li>Chawin Sitawarin (Meta)</li>
                                        <li>Clarence Chio (UC Berkeley)</li>
                                        <li>Daniel Gibert (University College Dublin, CeADAR)</li>
                                        <li>Daniele Canavese (IRIT)</li>
                                        <li>Daniele Friolo (Sapienza University of Rome)</li>
                                        <li>Daniele Angioni (University of Cagliari)</li>
                                        <li>David Pape (CISPA Helmholtz Center for Information Security)</li>
                                        <li>Dongdong She (Hong Kong University of Science and Technology)</li>
                                        <li>Dorjan Hitaj (Sapienza University of Rome)</li>
                                        <li>Edoardo Debenedetti (ETH Zurich)</li>
                                        <li>Fabio De Gaspari (Sapienza University of Rome)</li>
                                        <li>Francesco Flammini (IDSIA USI-SUPSI)</li>
                                        <li>Giorgio Severi (Northeastern University)</li>
                                        <li>Giovanni Cherubin (Microsoft)</li>
                                        <li>Giovanni Apruzzese (University of Liechtenstein)</li>
                                        <li>Giulio Zizzo (IBM Research)</li>
                                        <li>Giuseppina Andresini (University of Bari Aldo Moro)</li>
                                        <li>Hamid Bostani (Radboud University, The Netherlands)</li>
                                        <li>Hari Venugopalan (University of California, Davis)</li>
                                        <li>Javier Carnerero Cano (IBM Research Europe/Imperial College London)</li>
                                        <li>Jonas Ricker (Ruhr University Bochum)</li>
                                        <li>Julien Piet (UC Berkeley)</li>
                                        <li>Junhao Dong (Nanyang Technological University)</li>
                                        <li>Kexin Pei (The University of Chicago)</li>
                                        <li>Konrad Rieck (TU Berlin)</li>
                                        <li>LE MERRER Erwan (Inria, France)</li>
                                    </ul>
                                </div>
                                <div class="col">
                                    <ul class="noindent">
                                        <li>Lei Ma (The University of Tokyo / University of Alberta)</li>
                                        <li>Leonardo Regano (University Of Cagliari)</li>
                                        <li>Lorenzo Pisu (University Of Cagliari)</li>
                                        <li>Luis Muñoz-González (Telefónica Research)</li>
                                        <li>Luke Richards (University of Maryland, Baltimore County)</li>
                                        <li>Markus Dürmuth (Leibniz University Hannover)</li>
                                        <li>Marta Catillo (Università degli Studi del Sannio)</li>
                                        <li>Matthew Jagielski (Google Research)</li>
                                        <li>Maura Pintor (University of Cagliari)</li>
                                        <li>Mauro Conti (University of Padua)</li>
                                        <li>Melody Wolk (Apple)</li>
                                        <li>Milenko Drinic (Microsoft Corporation)</li>
                                        <li>Muhammad Zaid Hameed (IBM Research Europe, Ireland)</li>
                                        <li>Ozan Özdenizci (Montanuniversität Leoben)</li>
                                        <li>Pablo Moriano (Oak Ridge National Laboratory)</li>
                                        <li>Pavel Laskov (University of Liechtenstein)</li>
                                        <li>Pooria Madani (Ontario Tech University)</li>
                                        <li>Pratyusa K. Manadhata (Meta)</li>
                                        <li>Quan Le (CeADAR, University College Dublin)</li>
                                        <li>SHRIKANT TANGADE (University of Padova, Italy & CHRIST University, India)</li>
                                        <li>Sahar Abdelnabi (Microsoft)</li>
                                        <li>Sanghyun Hong (Oregon State University)</li>
                                        <li>Savino Dambra (Norton Research Group)</li>
                                        <li>Shujiang Wu (F5. Inc)</li>
                                        <li>Silvia Lucia Sanna (University of Cagliari)</li>
                                        <li>Simon Oya (The University of British Columbia (UBC))</li>
                                        <li>Simos Gerasimou (University of York. UK)</li>
                                        <li>Sivanarayana Gaddam (Cohesity Inc)</li>
                                        <li>Sizhe Chen (UC Berkeley)</li>
                                        <li>Tianhao Wang (University of Virginia)</li>
                                        <li>Vera Rimmer (KU Leuven)</li>
                                        <li>Vikash Sehwag (Sony AI)</li>
                                        <li>Vinod P. (University of Padua, Italy)</li>
                                        <li>Wenxin Ding (University of Chicago)</li>
                                        <li>Xiaofei Xie (Singapore Management University)</li>
                                        <li>Yang Zhang (CISPA Helmholtz Center for Information Security)</li>
                                        <li>Yash Vekaria (University of California, Davis)</li>
                                        <li>Yufei Han (INRIA)</li>
                                        <li>Zeliang Kan (King's College London)</li>
                                    </ul>
                                </div>
                            </div>
                            <p>
                                <!-- We are currently looking for reviewers. Contact
                                <a href="mailto:maura.pintor@unica.it">maura.pintor@unica.it</a>
                                if you want to be involved. -->
                                Thanks for those who contacted us to help with the reviews!
                            </p>
                        </div>
                    </div>
                </div>
            </section>
            <!-- Footer -->
            <footer>
                <div class="container">
                    <div class="row">
                        <div class="col-md-6">
                            <span class="copyright">Copyright © AISec 2024</span>
                            <br>
                        </div>
                        <div class="col-md-6">
                            Support kindly provided by the
                            <a href="https://www.unica.it/unica/en/homepage.page/" target="_blank">University of Cagliari</a>
                            and by the
                            <a href="https://elsa-ai.eu" target="_blank">
                                ELSA project
                            </a>
                            .
                            <br>
                            <img src="https://web.unica.it/UserFiles/File/Utenti/verdeoro/unica_800_black.png" height="50em" style="margin: 10px;">
                            <img src="img/elsa_logo_RGB_twocolor-300x272.png" height="50em" style="margin: 10px;">
                        </div>
                    </div>
                </div>
            </footer>
            <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
            <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ENjdO4Dr2bkBIFxQpeoTz1HIcje39Wm4jDKdf19U8gI4ddQ3GYNS7NTKfAdVQSZe" crossorigin="anonymous"></script>
            <script src="js/agency.min.js"></script>
        </body>
    </html>
